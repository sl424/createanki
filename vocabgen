#!/usr/bin/env python3
import genanki
import random
import sys
from getopt import getopt
from jisho import jisho_get
from models import vocab_model
from rtk import rtk
from tqdm import tqdm
from wordfreq import wordfreq

tags = ["#common", "#words"]
jlpt_min = -1
jlpt_max = -1
deck_name = None
translate_grammar = True
sort_by_freq = True

opts, args = getopt(sys.argv[1:], "RTGr:t:j:n:h")

help_text = f"""
Usage: {sys.argv[0]} [-FRTGh] [-n <name>] [-t <tags...>] [-j <n[-n]>] <output.apkg>

Generates an Anki deck for Japanese vocabulary study.

Cards are generated by looking up vocabulary with the specified tags in RTK
order. A local cache is kept based on unique kanji and tag combinations. The
first time you generate decks based on this cache, it may be slower, but
subsequent runs will be faster. You can't configure where the cache is. You
can't deduplicate it. Suck it up or send a patch.

-F: disable word frequency sorting (RTK order is used instead).
-T: disable default tags (#common #words). Specify before -t.
-G: show grammatical terms in English.
-n <name>: deck name
-t <tags...>: refine to vocab matching tags (comma separated).
-j <n[-n]>: limit to JLPT levels n (thru n). No default.
""".strip()

for opt, val in opts:
    if opt == "-h":
        print(help_text)
        sys.exit(0)
    elif opt == "-F":
        sort_by_freq
    elif opt == "-T":
        tags = []
    elif opt == "-G":
        translate_grammar = True
    elif opt == "-t":
        tags = val.split(",") + tags
    elif opt == "-n":
        deck_name = val
    elif opt == "-j":
        levels = val.split("-")
        if len(levels) == 1:
            jlpt_min = int(levels[0])
            jlpt_max = int(levels[0])
        elif len(levels) == 2:
            jlpt_min = int(levels[0])
            jlpt_max = int(levels[1])
        if (len(levels) > 2
                or not 1 <= jlpt_min <= 5
                or not 1 <= jlpt_max <= 5
                or jlpt_min > jlpt_max):
            sys.stderr.write("Error: Invalid JLPT range. "
                + f"See {sys.argv[0]} -h for help\n")
            sys.exit(1)
    else:
        sys.stderr.write("Error: unknown option {opt}. "
            + f"See {sys.argv[0]} -h for help\n")
        sys.exit(1)

if len(args) != 1:
    sys.stderr.write("Error: missing output file. "
        + f"See {sys.argv[0]} -h for help\n")
    sys.exit(1)

output = args[0]

def jlpt_filter(w):
    if jlpt_min == -1:
        return True
    if len(w["jlpt"]) == 0:
        return False
    wmin = min(int(j[-1]) for j in w["jlpt"])
    wmax = max(int(j[-1]) for j in w["jlpt"])
    return wmin <= jlpt_min <= wmax

pos_map = {
    "godan verb with ru ending": "る五段",
    "godan verb with mu ending": "む五段",
    "noun": "名詞",
    "suru verb": "する動詞",
    "intransitive verb": "自動詞",
    "no-adjective": "の",
    "na-adjective": "形容動詞",
    "i-adjective": "形容詞",
    "temporal noun": "時名詞",
    "place": "場所",
    "prefix": "接頭辞",
    "numeric": "数字",
    "adverbial noun": "副詞名詞",
    "adverb": "副詞",
    "suffix": "接尾辞",
    "prefix": "接頭辞",
    "conjunction": "接続詞",
}

tags_map = {
    "usually written using kana alone": "一般的ではかなだけを使う",
}

def gen_parts_of_speech(sense):
    pos = sense["parts_of_speech"]
    if not any(pos):
        return ""
    if translate_grammar:
        text = "、".join(pos_map.get(p.lower()) or p for p in pos)
    else:
        text = ", ".join(pos)
    return f" <span class='pos'>{text}</span>"

def gen_tags(sense):
    tags = sense["tags"]
    if not any(tags):
        return ""
    if translate_grammar:
        text = "、".join(tags_map.get(t.lower()) or t for t in tags)
    else:
        text = ", ".join(tags)
    return f"<br /><span class='tags'>{text}</span>"

def gen_info(sense):
    info = sense["info"]
    if not any(info):
        return ""
    text = ", ".join(info)
    return f"<br /><span class='info'>{text}</span>"

def filter_sense(sense):
    pos = sense["parts_of_speech"]
    if pos == ["Wikipedia definition"]:
        return False
    # TODO: Other criteria?
    return True

def jword_sort_key(word):
    unsorted = 999999999
    wordfreq_index = unsorted
    rtk_index = unsorted

    if word in wordfreq:
        wordfreq_index = wordfreq[word]
    rtk_index = min(rtk.index(ch) if ch in rtk else unsorted for ch in word)

    if sort_by_freq:
        return wordfreq_index
    else:
        return rtk_index

def word_sort_key(word):
    jwords = set([
        w["word"] if "word" in w else w["reading"] for w in word['japanese']
    ])
    return min(jword_sort_key(w) for w in jwords)

seen = set()
def gen_note(word):
    jwords = set([
        w["word"] if "word" in w else w["reading"] for w in word['japanese']
    ])
    # Sort so that RTK kanji words are always shown first
    jwords = sorted(jwords, key=jword_sort_key)
    readings = set(w["reading"]
            if "reading" in w else w["word"] for w in word['japanese'])
    senses = word["senses"][:5]
    ewords = [
        ", ".join(s["english_definitions"])
            + gen_parts_of_speech(s)
            + gen_tags(s)
            + gen_info(s)
        for s in senses if filter_sense(s)
    ]
    japanese = ", ".join(jwords)
    english = "<ol>" + "".join(f"<li>{w}</li>" for w in ewords) + "</ol>"

    # Force readings if normally written with kana alone
    include_readings = any(
            "Usually written using kana alone" in s["tags"] for s in senses)
    if include_readings:
        for r in readings:
            if r not in japanese:
                japanese = f"{r}, {japanese}"

    readings = ", ".join(readings)
    slug = word["slug"]

    if japanese in seen:
        return None
    seen.update([japanese])

    return genanki.Note(
        model=vocab_model,
        fields=[japanese, english, readings, slug])

if not deck_name:
    deck_name = "Japanese"
    if jlpt_min != -1 and jlpt_max != jlpt_min:
        deck_name += f" JLPT{jlpt_min}-{jlpt_max}"
    elif jlpt_min != -1:
        deck_name += f" JLPT{jlpt_min}"
    if any(tags):
        deck_name += " " + " ".join(tags)

deck = genanki.Deck(random.randrange(1 << 30, 1 << 31), deck_name)

words = list()
for kanji in tqdm(rtk):
    results = jisho_get(kanji, tags=tags)
    filtered = [w for w in results["data"] if jlpt_filter(w)]
    words += filtered

words = sorted(words, key=word_sort_key)

for word in words:
    note = gen_note(word)
    if note:
        deck.add_note(note)

genanki.Package(deck).write_to_file(output)
